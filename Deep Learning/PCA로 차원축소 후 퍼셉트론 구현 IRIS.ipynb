{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-frontier",
   "metadata": {},
   "source": [
    "## IRIS 데이터셋을 이용한 퍼셉트론 구현\n",
    "\n",
    "1. IRIS 데이터셋을 로드하시오.\n",
    "\n",
    "2. 로드한 데이터 셋을 학습용/검증용(train/test)으로 나누시오\n",
    "\n",
    "3. 학습용 데이터를 PCA를 이용하여 2차원으로 차원 축소를 진행하시오,.\n",
    "\n",
    "4. 2차원으로 축소된 데이터로 붓꽃을 분류하는 퍼셉트론 알고리즘을 학습을 통해 구현하시오.\n",
    "\n",
    "5. 검증용 셋으로 검증을 수행하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accessible-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_breast_cancer()\n",
    "\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ahead-channel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ed6d0fc250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alleged-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1160.1425737  -293.91754364]\n",
      " [1269.12244319   15.63018184]\n",
      " [ 995.79388896   39.15674324]\n",
      " ...\n",
      " [ 314.50175618   47.55352518]\n",
      " [1124.85811531   34.12922497]\n",
      " [-771.52762188  -88.64310636]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# n_components : 재구성할 차원 수\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# 고유 벡터의 축을 찾는다\n",
    "pca.fit(X)\n",
    "\n",
    "# 축에 맞게 변화된다\n",
    "X_pca = pca.transform(X)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cross-factory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ed6d1d7c40>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_pca[:,0], X_pca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expressed-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([443782.6051466 ,   7310.10006165])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "divine-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467, 0.01617649])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유벡터의 어느 축으로 얼마나 흩어져 있는지 백분율\n",
    "# 두번째 축은 정보가 얼마 없네~\n",
    "# [1차원, 2차원]\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "connected-atlanta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n",
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.feature_names)\n",
    "print(iris_data.target_names)\n",
    "print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-champagne",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X, columns = iris_data.feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "# units의 수\n",
    "print(len(df[\"target\"].unique()))\n",
    "\n",
    "# input_shape의 수\n",
    "print(len(iris_data.feature_names))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "supposed-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "iris_pca_train = pca.transform(X_train) # Train입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "harmful-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X_test)\n",
    "\n",
    "iris_pca_test = pca.transform(X_test) # Test입력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "political-characterization",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22076943,  0.30646406],\n",
       "       [ 1.52201038,  0.10219503],\n",
       "       [ 2.37344318, -0.17084102],\n",
       "       [-2.50943024,  0.20929643],\n",
       "       [-2.55466851, -0.14515852],\n",
       "       [-2.75249957,  0.15011288],\n",
       "       [ 0.45055121,  0.29461185],\n",
       "       [ 0.54738359,  0.65511015],\n",
       "       [ 2.68325184, -0.61098645],\n",
       "       [ 0.01962239,  0.65060235],\n",
       "       [ 0.86644514, -0.1427507 ],\n",
       "       [-2.66840869,  0.34085604],\n",
       "       [-2.55682173,  0.22305852],\n",
       "       [-2.54439034, -1.03343254],\n",
       "       [-2.34257735, -0.13540972],\n",
       "       [-2.55442452, -0.6215641 ],\n",
       "       [ 1.00046488, -0.5305583 ],\n",
       "       [-2.63605207,  0.24572191],\n",
       "       [-2.44092832, -0.63117308],\n",
       "       [ 1.86559043,  0.45842003],\n",
       "       [ 0.65615288,  0.54243343],\n",
       "       [ 0.72927136,  0.39177605],\n",
       "       [ 3.46911073, -0.63541818],\n",
       "       [-0.61590727,  0.98026916],\n",
       "       [ 1.00008075, -0.33398666],\n",
       "       [ 1.35689026, -0.76081767],\n",
       "       [ 1.3827872 ,  0.2486993 ],\n",
       "       [ 1.03528483,  0.43233673],\n",
       "       [ 0.59604969,  1.2530187 ],\n",
       "       [-2.66219299, -0.28738949],\n",
       "       [ 1.15867506, -0.26897463],\n",
       "       [-2.73301809, -0.22511521],\n",
       "       [-2.58476806, -1.17448094],\n",
       "       [ 0.31729974,  0.28927617],\n",
       "       [ 1.12302424, -0.30695528],\n",
       "       [ 1.26570507,  0.65657236],\n",
       "       [ 2.48732351, -0.37702164],\n",
       "       [ 2.91982518, -0.48322525],\n",
       "       [ 1.4569065 ,  0.31953981],\n",
       "       [-2.22234117, -0.69000193],\n",
       "       [ 1.98299592, -0.43004164],\n",
       "       [ 0.90662012,  0.25023486],\n",
       "       [-2.58053564, -0.28809717],\n",
       "       [ 3.5789286 , -0.58157031],\n",
       "       [ 2.41434518,  0.05346968],\n",
       "       [-3.1449599 ,  0.53896323],\n",
       "       [-0.41169056,  1.20316449],\n",
       "       [-2.54192701,  0.02459662],\n",
       "       [ 1.64760693,  0.59632815],\n",
       "       [ 2.46466469, -0.5521576 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X_train)\n",
    "pca.fit(X_test)\n",
    "iris_pca_train = pca.transform(X_train) # Train입력\n",
    "iris_pca_test = pca.transform(X_test) # Test입력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "genuine-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/100 [..............................] - ETA: 0s - loss: 3.8264 - acc: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.2931 - acc: 0.6100\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0919 - acc: 0.6500\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0813 - acc: 0.6600\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0954 - acc: 0.6600\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0605 - acc: 0.6600\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0529 - acc: 0.6600\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0533 - acc: 0.6600\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0702 - acc: 0.6600\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0553 - acc: 0.6600\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0588 - acc: 0.6600\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0558 - acc: 0.6600\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0593 - acc: 0.6600\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0596 - acc: 0.6600\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0535 - acc: 0.6600\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0647 - acc: 0.6600\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0664 - acc: 0.6600\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0531 - acc: 0.6600\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0522 - acc: 0.6600\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0554 - acc: 0.6600\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0657 - acc: 0.6600\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0488 - acc: 0.6600\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0499 - acc: 0.6600\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0531 - acc: 0.6600\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0490 - acc: 0.6600\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.0529 - acc: 0.6600\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0509 - acc: 0.6600\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0554 - acc: 0.6600\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0503 - acc: 0.6600\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0677 - acc: 0.6600\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0793 - acc: 0.6727    - 0s 910us/step - loss: 0.0600 - acc: 0.6600\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0504 - acc: 0.6600\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0556 - acc: 0.6600\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0569 - acc: 0.6600\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0565 - acc: 0.6600\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0463 - acc: 0.6600\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0477 - acc: 0.6600\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0441 - acc: 0.6600\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0480 - acc: 0.6600\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0450 - acc: 0.6600\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0490 - acc: 0.6600\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0456 - acc: 0.6600\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0469 - acc: 0.6600\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0413 - acc: 0.6600\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0445 - acc: 0.6600\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0473 - acc: 0.6600\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.0421 - acc: 0.6600\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0433 - acc: 0.6600\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0382 - acc: 0.6600\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0360 - acc: 0.6600\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0373 - acc: 0.6600\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0447 - acc: 0.6600\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0351 - acc: 0.6600\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.0364 - acc: 0.6600\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0344 - acc: 0.6600\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0349 - acc: 0.6600\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0356 - acc: 0.6600\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0393 - acc: 0.6600\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0364 - acc: 0.6600\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0321 - acc: 0.6600\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0393 - acc: 0.6600\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0336 - acc: 0.6600\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0297 - acc: 0.6600\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0389 - acc: 0.6600\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0345 - acc: 0.6600\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0347 - acc: 0.6600\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0338 - acc: 0.6600\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0302 - acc: 0.6600\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.0375 - acc: 0.6600\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0282 - acc: 0.6600\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0330 - acc: 0.6600\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0319 - acc: 0.6600\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0413 - acc: 0.6600\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0340 - acc: 0.6600\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0319 - acc: 0.6600\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0396 - acc: 0.6600\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0319 - acc: 0.6600\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0309 - acc: 0.6600\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0322 - acc: 0.6600\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0330 - acc: 0.6600\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 870us/step - loss: 0.0334 - acc: 0.6600\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0431 - acc: 0.6600\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0362 - acc: 0.6600\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0297 - acc: 0.6600\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0363 - acc: 0.6600\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0287 - acc: 0.6600\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.0289 - acc: 0.6600\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0354 - acc: 0.6600\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0295 - acc: 0.6600\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0254 - acc: 0.6600\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0312 - acc: 0.6600\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0259 - acc: 0.6600\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0264 - acc: 0.6600\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0316 - acc: 0.6600\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.0301 - acc: 0.6600\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0340 - acc: 0.6600\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0324 - acc: 0.6600\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0257 - acc: 0.6600\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0284 - acc: 0.6600\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0270 - acc: 0.6600\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0270 - acc: 0.6600 \n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 836us/step - loss: 0.0375 - acc: 0.6600\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0291 - acc: 0.6600\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0275 - acc: 0.6600\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 821us/step - loss: 0.0325 - acc: 0.6600\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.0332 - acc: 0.6600\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 756us/step - loss: 0.0273 - acc: 0.6600 \n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 809us/step - loss: 0.0228 - acc: 0.6600\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0314 - acc: 0.6600\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0267 - acc: 0.6600\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0238 - acc: 0.6600\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 825us/step - loss: 0.0267 - acc: 0.6600\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 793us/step - loss: 0.0254 - acc: 0.6600\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0253 - acc: 0.6600\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0240 - acc: 0.606 - 0s 804us/step - loss: 0.0242 - acc: 0.6600\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 829us/step - loss: 0.0264 - acc: 0.6600\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0238 - acc: 0.6600\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0307 - acc: 0.6600\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0341 - acc: 0.6600\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0258 - acc: 0.6600\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.0219 - acc: 0.6600\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0279 - acc: 0.6600\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0260 - acc: 0.6600\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0269 - acc: 0.6600\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0277 - acc: 0.6600\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0262 - acc: 0.6600\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0221 - acc: 0.6600\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0275 - acc: 0.6600\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 825us/step - loss: 0.0215 - acc: 0.6600\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 849us/step - loss: 0.0230 - acc: 0.6600\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0252 - acc: 0.6600 \n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0275 - acc: 0.6600\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.0236 - acc: 0.6600\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0241 - acc: 0.6600\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0237 - acc: 0.6600\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0210 - acc: 0.6600\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0254 - acc: 0.6600\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 580us/step - loss: 0.0206 - acc: 0.6600\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 630us/step - loss: 0.0249 - acc: 0.6600\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0211 - acc: 0.6600 \n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0251 - acc: 0.6600\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.0238 - acc: 0.6600\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0250 - acc: 0.6600\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 741us/step - loss: 0.0187 - acc: 0.6600\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0243 - acc: 0.6600\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0195 - acc: 0.6600\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0184 - acc: 0.6600\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0179 - acc: 0.6600\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0219 - acc: 0.6600\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0191 - acc: 0.6600\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 775us/step - loss: 0.0237 - acc: 0.6600\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 802us/step - loss: 0.0193 - acc: 0.6600\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0278 - acc: 0.6600\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0188 - acc: 0.6600\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0142 - acc: 0.6600\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0259 - acc: 0.6600\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 796us/step - loss: 0.0183 - acc: 0.6600\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.0167 - acc: 0.6600\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 851us/step - loss: 0.0196 - acc: 0.6600\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.0192 - acc: 0.6600\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0165 - acc: 0.6600\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0159 - acc: 0.6600\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0197 - acc: 0.6600\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0219 - acc: 0.6600\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0220 - acc: 0.6600\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0221 - acc: 0.6600\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0168 - acc: 0.6600\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0173 - acc: 0.6600\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 805us/step - loss: 0.0158 - acc: 0.6600\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 885us/step - loss: 0.0195 - acc: 0.6600\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0164 - acc: 0.6600\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0155 - acc: 0.6600\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0201 - acc: 0.6600 \n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0147 - acc: 0.6600\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0303 - acc: 0.6600\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0110 - acc: 0.6600\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0183 - acc: 0.6600\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0161 - acc: 0.6600\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0157 - acc: 0.6600 \n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0139 - acc: 0.6600\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0117 - acc: 0.6600\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 817us/step - loss: 0.0129 - acc: 0.6600\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 871us/step - loss: 0.0092 - acc: 0.6600\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.0160 - acc: 0.6600\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.6600\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0097 - acc: 0.6600\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0105 - acc: 0.6600\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0195 - acc: 0.6600\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0111 - acc: 0.6600\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0080 - acc: 0.6600\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0060 - acc: 0.6600\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0152 - acc: 0.6600\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0126 - acc: 0.6600\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0068 - acc: 0.6600\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0192 - acc: 0.6600\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0082 - acc: 0.6600\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0100 - acc: 0.6600\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.0149 - acc: 0.6600\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0118 - acc: 0.6500\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0117 - acc: 0.6600\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0137 - acc: 0.6600\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0073 - acc: 0.6600 \n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0071 - acc: 0.6600\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0075 - acc: 0.6600\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0057 - acc: 0.6600 \n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0049 - acc: 0.6600\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0079 - acc: 0.6600\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0062 - acc: 0.6600\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0047 - acc: 0.6600\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0082 - acc: 0.6600\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0147 - acc: 0.6600\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0040 - acc: 0.6600\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0068 - acc: 0.6600\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0227 - acc: 0.6600\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0184 - acc: 0.6600\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0121 - acc: 0.6600 \n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0124 - acc: 0.6600\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 0.6600\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0035 - acc: 0.6600\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 620us/step - loss: 0.0056 - acc: 0.6600\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0142 - acc: 0.6600\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 590us/step - loss: 0.0086 - acc: 0.6600\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0134 - acc: 0.6600\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0067 - acc: 0.6600\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0067 - acc: 0.6600\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0032 - acc: 0.6600\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0068 - acc: 0.6600\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0155 - acc: 0.6600\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0181 - acc: 0.6600\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0045 - acc: 0.6600\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0048 - acc: 0.6600\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0085 - acc: 0.6600\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0049 - acc: 0.6600\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0013 - acc: 0.6600\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0086 - acc: 0.6600\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0035 - acc: 0.6600\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0025 - acc: 0.6600 \n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0084 - acc: 0.6600\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 0.6600\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0035 - acc: 0.6600\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 820us/step - loss: 0.0034 - acc: 0.6600\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0097 - acc: 0.6600 \n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0057 - acc: 0.6600\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0124 - acc: 0.6600\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0015 - acc: 0.6600 \n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0022 - acc: 0.6600 \n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0162 - acc: 0.6600\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0118 - acc: 0.6600\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0024 - acc: 0.6600\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0012 - acc: 0.6600\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0070 - acc: 0.6600\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0190 - acc: 0.6600 \n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0117 - acc: 0.6600\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0274 - acc: 0.6600\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0200 - acc: 0.6600\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0050 - acc: 0.6600\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0037 - acc: 0.6600 \n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0017 - acc: 0.6600\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 6.6754e-04 - acc: 0.6600\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 3.0750e-04 - acc: 0.6600\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 2.5026e-04 - acc: 0.6600\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 1.6401e-04 - acc: 0.6600\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6169e-04 - acc: 0.6600\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0161e-04 - acc: 0.6600\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 1.5324e-04 - acc: 0.6600\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.3456e-04 - acc: 0.6600\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 610us/step - loss: 1.3108e-04 - acc: 0.6600\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 640us/step - loss: 1.8062e-04 - acc: 0.6600\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 1.8012e-04 - acc: 0.6600\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 2.1437e-04 - acc: 0.6600\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0093 - acc: 0.6600\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0398 - acc: 0.6600\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 620us/step - loss: 0.0226 - acc: 0.6600\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0129 - acc: 0.6600\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0062 - acc: 0.6600\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 610us/step - loss: 0.0106 - acc: 0.6600\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0143 - acc: 0.6600\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0078 - acc: 0.6600\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0050 - acc: 0.6600\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0031 - acc: 0.6600\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0013 - acc: 0.6600\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0042 - acc: 0.6600 \n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0101 - acc: 0.6600 \n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 0.6600  \n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0072 - acc: 0.6600\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0013 - acc: 0.6600 \n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 9.2526e-04 - acc: 0.6600\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0061 - acc: 0.6600\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0053 - acc: 0.6600 \n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 1.8746e-04 - acc: 0.6600\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 2.9676e-04 - acc: 0.6600\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 3.9674e-04 - acc: 0.6600\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 4.6867e-04 - acc: 0.6600\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 768us/step - loss: 6.7214e-04 - acc: 0.6600\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 729us/step - loss: 3.1566e-04 - acc: 0.6600\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 747us/step - loss: 8.0790e-05 - acc: 0.6600\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 794us/step - loss: 5.3453e-05 - acc: 0.6600\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 743us/step - loss: 6.1881e-05 - acc: 0.6600\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 873us/step - loss: 4.1506e-05 - acc: 0.6600\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 851us/step - loss: 7.1880e-05 - acc: 0.6600\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 807us/step - loss: 3.2203e-05 - acc: 0.6600\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 814us/step - loss: 1.6133e-05 - acc: 0.6600\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 854us/step - loss: 2.0762e-05 - acc: 0.6600\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 828us/step - loss: 2.4178e-05 - acc: 0.6600\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 816us/step - loss: 3.7416e-05 - acc: 0.6600\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 2.2137e-05 - acc: 0.6600\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 3.2156e-05 - acc: 0.6600\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 5.1147e-05 - acc: 0.6600\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 6.6255e-05 - acc: 0.6600\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.6369e-05 - acc: 0.6600\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.8156e-05 - acc: 0.6600\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2359e-04 - acc: 0.6600\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 1.9150e-04 - acc: 0.6600\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 2.5848e-04 - acc: 0.6600\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 5.4454e-04 - acc: 0.6600\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 5.2763e-04 - acc: 0.6600\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0059 - acc: 0.6600\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0610 - acc: 0.6600\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 769us/step - loss: 0.0318 - acc: 0.6600\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 858us/step - loss: 0.0253 - acc: 0.6600\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0179 - acc: 0.6600\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0244 - acc: 0.6600\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0215 - acc: 0.6600\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 783us/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 847us/step - loss: 0.0220 - acc: 0.6600\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0078 - acc: 0.6600\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.0055 - acc: 0.6600 \n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0043 - acc: 0.6600\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0061 - acc: 0.6600\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 815us/step - loss: 0.0051 - acc: 0.6600\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 795us/step - loss: 0.0031 - acc: 0.6600\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.0025 - acc: 0.6600\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 878us/step - loss: 2.5193e-04 - acc: 0.6600\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 1.0038e-04 - acc: 0.6600\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 789us/step - loss: 7.4250e-05 - acc: 0.6600\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 762us/step - loss: 7.0842e-05 - acc: 0.6600\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 816us/step - loss: 5.0146e-05 - acc: 0.6600\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 859us/step - loss: 4.0021e-05 - acc: 0.6600\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 873us/step - loss: 3.8081e-05 - acc: 0.6600\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 3.8326e-05 - acc: 0.6600\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 3.3711e-05 - acc: 0.6600\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 2.5523e-05 - acc: 0.6600\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 2.4190e-05 - acc: 0.6600\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 1.9063e-05 - acc: 0.6600\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 1.7678e-05 - acc: 0.6600\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 2.1050e-05 - acc: 0.6600ETA: 0s - loss: 2.4886e-05 - acc: 0.7119   \n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.3698e-05 - acc: 0.6600\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.8422e-05 - acc: 0.6600\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.1007e-05 - acc: 0.6600\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 8.9290e-06 - acc: 0.6600\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 861us/step - loss: 9.7717e-06 - acc: 0.6600\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 828us/step - loss: 8.5937e-06 - acc: 0.6600\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 835us/step - loss: 9.3736e-06 - acc: 0.6600\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 855us/step - loss: 9.1667e-06 - acc: 0.6600\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 772us/step - loss: 1.1560e-05 - acc: 0.6600\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.1844e-05 - acc: 0.6600\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.3964e-05 - acc: 0.6600\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1481e-06 - acc: 0.6600\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1897e-06 - acc: 0.6600\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.8481e-06 - acc: 0.6600\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 5.9442e-06 - acc: 0.6600\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9499e-05 - acc: 0.6600\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7668e-05 - acc: 0.6600\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5192e-05 - acc: 0.6600\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.2676e-06 - acc: 0.6600\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6500e-05 - acc: 0.6600\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6589e-05 - acc: 0.6600\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 0.6600\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0343 - acc: 0.6600\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.0535 - acc: 0.6600 \n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0300 - acc: 0.6600\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 1000us/step - loss: 0.0260 - acc: 0.6600\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0254 - acc: 0.6600\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0218 - acc: 0.6600\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0167 - acc: 0.6600\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0122 - acc: 0.6600\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0217 - acc: 0.6600\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 0.6600  \n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0076 - acc: 0.6600\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0194 - acc: 0.6600\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0081 - acc: 0.6600\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0096 - acc: 0.6600 \n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0029 - acc: 0.6600\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0040 - acc: 0.6600\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0011 - acc: 0.6600\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.0069 - acc: 0.6600\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 630us/step - loss: 7.6268e-04 - acc: 0.6600\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.7378e-04 - acc: 0.6600\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 6.2959e-05 - acc: 0.6600\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 4.7579e-05 - acc: 0.6600\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 4.6061e-05 - acc: 0.6600\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 4.3773e-05 - acc: 0.6600\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 2.7243e-05 - acc: 0.6600\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 3.8608e-05 - acc: 0.6600\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 2.5229e-05 - acc: 0.6600\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 2.1705e-05 - acc: 0.6600\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 770us/step - loss: 2.1937e-05 - acc: 0.6600\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 3.6909e-05 - acc: 0.6600\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 5.5234e-05 - acc: 0.6600\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 1.3519e-05 - acc: 0.6600\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 1.4404e-05 - acc: 0.6600\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 4.1268e-05 - acc: 0.6600\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.3494e-05 - acc: 0.6600\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 1.1447e-05 - acc: 0.6600\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 1.3871e-05 - acc: 0.6600\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.2910e-05 - acc: 0.6600\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 8.7566e-06 - acc: 0.6600\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1224e-06 - acc: 0.6600\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.5364e-06 - acc: 0.6600\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2290e-04 - acc: 0.6600\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.4365e-04 - acc: 0.6600\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.4995e-05 - acc: 0.6600\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 4.3708e-06 - acc: 0.6600\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 6.8082e-06 - acc: 0.6600\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 1.2781e-05 - acc: 0.6600\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 1.8894e-05 - acc: 0.6600\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 2.2744e-05 - acc: 0.6600\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 2.5327e-05 - acc: 0.6600\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 5.4501e-05 - acc: 0.6600\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 8.3503e-05 - acc: 0.6600\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 3.6946e-05 - acc: 0.6600\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.3233e-05 - acc: 0.6600\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2922e-05 - acc: 0.6600\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1561e-05 - acc: 0.6600\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9960e-05 - acc: 0.6600\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2460e-05 - acc: 0.6600\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3293e-05 - acc: 0.6600\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.6496e-05 - acc: 0.6600\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7526e-05 - acc: 0.6600\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7886e-05 - acc: 0.6600\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.4033e-04 - acc: 0.6600\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0152 - acc: 0.6600\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0632 - acc: 0.6600\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 0.6600\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0257 - acc: 0.6600\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0120 - acc: 0.6600\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0125 - acc: 0.6600\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0175 - acc: 0.6600\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0106 - acc: 0.6600\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0059 - acc: 0.6600 \n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0042 - acc: 0.6600\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.0056 - acc: 0.6600\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 1000us/step - loss: 0.0200 - acc: 0.6600\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0247 - acc: 0.6600\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0130 - acc: 0.6600\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0074 - acc: 0.6600\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0036 - acc: 0.6600\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0056 - acc: 0.6600 \n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0084 - acc: 0.6600\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0145 - acc: 0.6600\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0041 - acc: 0.6600\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 5.4795e-04 - acc: 0.6600\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 4.1880e-04 - acc: 0.6600\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 7.7556e-04 - acc: 0.6600\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0030 - acc: 0.6600 \n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0180 - acc: 0.6600\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0012 - acc: 0.6600\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0132 - acc: 0.6600\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0202 - acc: 0.6600 \n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0156 - acc: 0.6600\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0195 - acc: 0.6600\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.0048 - acc: 0.6600\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0119 - acc: 0.6600 \n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0043 - acc: 0.6600\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0029 - acc: 0.6600 \n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0013 - acc: 0.6600\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0333e-04 - acc: 0.6600\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 7.9003e-05 - acc: 0.6600\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 5.8534e-05 - acc: 0.6600\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 590us/step - loss: 5.4336e-05 - acc: 0.6600\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 620us/step - loss: 4.3827e-05 - acc: 0.6600\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 3.5381e-05 - acc: 0.6600\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 610us/step - loss: 3.4875e-05 - acc: 0.6600\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 610us/step - loss: 3.0956e-05 - acc: 0.6600\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 2.5200e-05 - acc: 0.6600\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 2.4269e-05 - acc: 0.6600\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 1.9121e-05 - acc: 0.6600\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.8297e-05 - acc: 0.6600\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 1.7075e-05 - acc: 0.6600\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 2.1135e-05 - acc: 0.6600\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.7748e-05 - acc: 0.6600\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.4397e-05 - acc: 0.6600\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 807us/step - loss: 9.8681e-06 - acc: 0.6600\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 746us/step - loss: 1.0266e-05 - acc: 0.6600\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 795us/step - loss: 8.5848e-06 - acc: 0.6600\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 1.1013e-05 - acc: 0.6600\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 7.4809e-06 - acc: 0.6600\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 7.3936e-06 - acc: 0.6600\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 1.0713e-05 - acc: 0.6600\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 6.0634e-05 - acc: 0.6600\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 3.5204e-05 - acc: 0.6600\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 1.5493e-05 - acc: 0.6600\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.4715e-05 - acc: 0.6600\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 4.0895e-05 - acc: 0.6600\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 3.0868e-05 - acc: 0.6600\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 1.4912e-05 - acc: 0.6600\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 1.4032e-05 - acc: 0.6600\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 3.5886e-05 - acc: 0.6600\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 2.3661e-05 - acc: 0.6600\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4420e-05 - acc: 0.6600\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.3593e-05 - acc: 0.6600\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 1.9462e-05 - acc: 0.6600\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 9.3840e-06 - acc: 0.6600\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 6.7805e-06 - acc: 0.6600\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 1.0804e-05 - acc: 0.6600\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 761us/step - loss: 8.5615e-05 - acc: 0.6600\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 792us/step - loss: 5.7062e-05 - acc: 0.6600\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 828us/step - loss: 2.1555e-04 - acc: 0.6600\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0080 - acc: 0.6190    - 0s 820us/step - loss: 0.0084 - acc: 0.6600\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 825us/step - loss: 0.0289 - acc: 0.6600\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 808us/step - loss: 0.0369 - acc: 0.6600\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0416 - acc: 0.6600\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0256 - acc: 0.6600\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0163 - acc: 0.6600\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 0.6600\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 0.6600\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0238 - acc: 0.6600\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0096 - acc: 0.6600\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0136 - acc: 0.6600\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0061 - acc: 0.6600\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0220 - acc: 0.6600\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 640us/step - loss: 0.0055 - acc: 0.6600\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0205 - acc: 0.6600 \n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0117 - acc: 0.6600\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0144 - acc: 0.6600\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 600us/step - loss: 0.0084 - acc: 0.6600 \n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0105 - acc: 0.6600 \n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0042 - acc: 0.6600\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0035 - acc: 0.6600\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0026 - acc: 0.6600\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0015 - acc: 0.6600\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0018 - acc: 0.6600 \n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0026 - acc: 0.6600\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0012 - acc: 0.6600 \n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0016 - acc: 0.6600 \n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0041 - acc: 0.6600 \n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.9095e-04 - acc: 0.6600\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 4.8591e-04 - acc: 0.6600\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0011 - acc: 0.6600 \n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0046 - acc: 0.6600\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0080 - acc: 0.6600\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 3.4016e-04 - acc: 0.6600\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 1.6255e-04 - acc: 0.6600\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 1.2017e-04 - acc: 0.6600\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 788us/step - loss: 9.4245e-05 - acc: 0.6600\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3048e-04 - acc: 0.666 - 0s 784us/step - loss: 9.4551e-05 - acc: 0.6600\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.9002e-05 - acc: 0.7333    - 0s 816us/step - loss: 7.9629e-05 - acc: 0.6600\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 869us/step - loss: 5.5567e-05 - acc: 0.6600\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 933us/step - loss: 5.4500e-05 - acc: 0.6600\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 5.0796e-05 - acc: 0.6600\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 3.8238e-05 - acc: 0.6600\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 3.9998e-05 - acc: 0.6600\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 2.4276e-05 - acc: 0.6600\n",
      "Epoch 557/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 780us/step - loss: 1.9969e-05 - acc: 0.6600\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3981e-05 - acc: 0.639 - 0s 840us/step - loss: 2.4888e-05 - acc: 0.6600\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 3.1124e-05 - acc: 0.6600\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 2.3619e-05 - acc: 0.6600\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.5261e-05 - acc: 0.6600\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 3.2550e-05 - acc: 0.6600\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 2.7325e-05 - acc: 0.6600\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 3.9655e-05 - acc: 0.6600\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 4.9240e-05 - acc: 0.6600\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.7565e-05 - acc: 0.6600\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 8.5402e-05 - acc: 0.6600\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 3.5213e-04 - acc: 0.6600\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 1.1199e-04 - acc: 0.6600\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 7.1397e-04 - acc: 0.6600\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0044 - acc: 0.6600\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0049 - acc: 0.6600\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 812us/step - loss: 0.0126 - acc: 0.6600 \n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.0222 - acc: 0.6600\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.0146 - acc: 0.6600\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0106 - acc: 0.66000 - ETA: 0s - loss: 0.0156 - acc: 0.6500       \n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 828us/step - loss: 0.0233 - acc: 0.6600\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 891us/step - loss: 7.7702e-04 - acc: 0.6600\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 887us/step - loss: 2.3077e-04 - acc: 0.6600\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 837us/step - loss: 3.9334e-05 - acc: 0.6600\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 2.7390e-05 - acc: 0.6600\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2200e-05 - acc: 0.7302    - 0s 794us/step - loss: 2.4812e-05 - acc: 0.6600\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 876us/step - loss: 1.8018e-05 - acc: 0.6600\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 749us/step - loss: 1.5445e-05 - acc: 0.6600\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 925us/step - loss: 1.5320e-05 - acc: 0.6600\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 1.5936e-05 - acc: 0.6600\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 1.1822e-05 - acc: 0.6600\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 1.0585e-05 - acc: 0.6600\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 8.8434e-06 - acc: 0.6600\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8256e-06 - acc: 0.6349    - 0s 830us/step - loss: 8.9490e-06 - acc: 0.6600\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 782us/step - loss: 8.0314e-06 - acc: 0.6600\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 868us/step - loss: 6.3629e-06 - acc: 0.6600\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 7.2102e-06 - acc: 0.6600\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 846us/step - loss: 5.9649e-06 - acc: 0.6600\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 5.5445e-06 - acc: 0.6600\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 857us/step - loss: 6.9146e-06 - acc: 0.6600\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 791us/step - loss: 5.5048e-06 - acc: 0.6600\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 773us/step - loss: 8.4950e-06 - acc: 0.6600\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 784us/step - loss: 7.4138e-06 - acc: 0.6600\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 817us/step - loss: 6.4721e-06 - acc: 0.6600\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 933us/step - loss: 1.6064e-05 - acc: 0.6600\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.6528e-06 - acc: 0.6600\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 630us/step - loss: 1.7004e-05 - acc: 0.6600\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 1.3673e-05 - acc: 0.6600\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 1.5389e-05 - acc: 0.6600\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 1.8239e-05 - acc: 0.6600\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 4.4029e-05 - acc: 0.6600\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 853us/step - loss: 8.8941e-05 - acc: 0.6600\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 1.7531e-05 - acc: 0.6600\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 2.0128e-05 - acc: 0.6600\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 3.3222e-06 - acc: 0.6600\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 2.5300e-06 - acc: 0.6600\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 798us/step - loss: 1.5614e-06 - acc: 0.6600\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 835us/step - loss: 3.0735e-06 - acc: 0.6600\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 804us/step - loss: 1.3807e-06 - acc: 0.6600\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 7.8629e-07 - acc: 0.6600\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.6904e-06 - acc: 0.6600\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 805us/step - loss: 1.3986e-06 - acc: 0.6600\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 899us/step - loss: 1.0656e-05 - acc: 0.6600\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 909us/step - loss: 5.8895e-05 - acc: 0.6600\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 777us/step - loss: 1.1281e-04 - acc: 0.6600\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 913us/step - loss: 9.6809e-04 - acc: 0.6600\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0268 - acc: 0.6600\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0253 - acc: 0.6600\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0181 - acc: 0.6600\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0137 - acc: 0.6600\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0211 - acc: 0.6600\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0512 - acc: 0.6600\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0317 - acc: 0.6600 \n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0280 - acc: 0.6600\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0213 - acc: 0.6600\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0141 - acc: 0.6600  \n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0100 - acc: 0.6600\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 750us/step - loss: 0.0146 - acc: 0.6600\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0226 - acc: 0.6600\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0099 - acc: 0.6600\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0092 - acc: 0.6600\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0060 - acc: 0.6600 \n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 8.6801e-04 - acc: 0.6600\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 3.8221e-04 - acc: 0.6600\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 2.5425e-04 - acc: 0.6600\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.9426e-04 - acc: 0.6600\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 1.0395e-04 - acc: 0.6600\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 7.6553e-05 - acc: 0.6600\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 980us/step - loss: 5.5896e-05 - acc: 0.6600\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 3.5682e-05 - acc: 0.6600\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 2.7964e-05 - acc: 0.6600\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.7107e-05 - acc: 0.6600\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 3.8647e-05 - acc: 0.6600\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 2.6718e-05 - acc: 0.6600\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 2.2277e-05 - acc: 0.6600\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.9602e-05 - acc: 0.6600\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 1.6603e-05 - acc: 0.6600\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 1.9470e-05 - acc: 0.6600\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 803us/step - loss: 2.4415e-05 - acc: 0.6600\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 0s 787us/step - loss: 2.8995e-05 - acc: 0.6600\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 2.7928e-05 - acc: 0.6600\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 2.4841e-05 - acc: 0.6600\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 3.5052e-05 - acc: 0.6600\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 847us/step - loss: 8.0407e-05 - acc: 0.6600\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 844us/step - loss: 1.5973e-04 - acc: 0.6600\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1670e-04 - acc: 0.6615    - 0s 770us/step - loss: 1.4947e-04 - acc: 0.6600\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 773us/step - loss: 1.2051e-04 - acc: 0.6600\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 9.5970e-05 - acc: 0.6600\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 8.0666e-05 - acc: 0.6600\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 764us/step - loss: 6.8721e-05 - acc: 0.6600\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 844us/step - loss: 4.2816e-05 - acc: 0.6600\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 847us/step - loss: 5.1562e-05 - acc: 0.6600\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 807us/step - loss: 4.3400e-05 - acc: 0.6600\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 815us/step - loss: 4.9080e-05 - acc: 0.6600\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 842us/step - loss: 9.9507e-05 - acc: 0.6600\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 924us/step - loss: 9.6648e-04 - acc: 0.6600\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 846us/step - loss: 0.0352 - acc: 0.6600\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 801us/step - loss: 0.0294 - acc: 0.6600\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 842us/step - loss: 0.0419 - acc: 0.6600\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0329 - acc: 0.6600\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.0304 - acc: 0.6600\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0284 - acc: 0.6600\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0261 - acc: 0.6600\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0254 - acc: 0.6600\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0220 - acc: 0.6600\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.0222 - acc: 0.6600\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0186 - acc: 0.6600\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0256 - acc: 0.6600\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0216 - acc: 0.6600 \n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0187 - acc: 0.6600\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 0.0191 - acc: 0.6600\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0181 - acc: 0.6600\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0169 - acc: 0.6600 \n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0183 - acc: 0.6600\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0158 - acc: 0.6600\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0170 - acc: 0.6600 \n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0135 - acc: 0.6600\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0150 - acc: 0.6600\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 735us/step - loss: 0.0108 - acc: 0.6600\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 739us/step - loss: 0.0193 - acc: 0.6600\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0144 - acc: 0.6600\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0126 - acc: 0.6600\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0164 - acc: 0.6600\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0125 - acc: 0.6600 \n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 829us/step - loss: 0.0133 - acc: 0.6600\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.7018    - 0s 860us/step - loss: 0.0139 - acc: 0.6600\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0139 - acc: 0.6600\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0130 - acc: 0.6600\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0114 - acc: 0.6600 \n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0105 - acc: 0.6600\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0100 - acc: 0.6600\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0100 - acc: 0.6600\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0116 - acc: 0.6600\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0086 - acc: 0.6600\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0103 - acc: 0.6600\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0100 - acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 798us/step - loss: 0.0067 - acc: 0.6600\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0077 - acc: 0.6600\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0076 - acc: 0.6600\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.0100 - acc: 0.6600\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0135 - acc: 0.6600\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0091 - acc: 0.6600\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.0036 - acc: 0.6600\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 0.6600  \n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0017 - acc: 0.6600\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0047 - acc: 0.6600\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0016 - acc: 0.6600\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 825us/step - loss: 9.2931e-04 - acc: 0.6600\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 853us/step - loss: 9.2407e-04 - acc: 0.6600\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0038 - acc: 0.6600\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0105 - acc: 0.6600\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.0083 - acc: 0.6600\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 816us/step - loss: 0.0224 - acc: 0.6600\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0041 - acc: 0.6600\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.0252 - acc: 0.6600 \n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0053 - acc: 0.6600\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 868us/step - loss: 0.0017 - acc: 0.6600\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.0027 - acc: 0.6600 \n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0016 - acc: 0.6600\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0010 - acc: 0.6600\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0013 - acc: 0.6600 \n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0020 - acc: 0.6364        - 0s 860us/step - loss: 0.0012 - acc: 0.6600\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0017 - acc: 0.6600\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0015 - acc: 0.6600\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0049 - acc: 0.6600\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0025 - acc: 0.6600\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0014 - acc: 0.6600\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0020 - acc: 0.6600\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 0.0055 - acc: 0.6600\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 7.7306e-04 - acc: 0.6600\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 802us/step - loss: 5.3670e-04 - acc: 0.6600\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 3.9309e-04 - acc: 0.6600\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 9.1501e-04 - acc: 0.6600\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0036 - acc: 0.6600\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.0212 - acc: 0.6600\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.0063 - acc: 0.6600\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.0036 - acc: 0.6600\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 9.7363e-04 - acc: 0.6600\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1970e-04 - acc: 0.6600\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 2.6439e-04 - acc: 0.6600\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 2.3617e-04 - acc: 0.6600\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.8395e-04 - acc: 0.6600\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 1.5185e-04 - acc: 0.6600\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 1.0579e-04 - acc: 0.6600\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 5.2660e-05 - acc: 0.6600\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 5.7280e-05 - acc: 0.6600\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 5.7467e-05 - acc: 0.6600\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 3.6202e-05 - acc: 0.6600\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 3.6773e-05 - acc: 0.6600\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.8072e-05 - acc: 0.6094    - 0s 790us/step - loss: 7.7352e-05 - acc: 0.6600\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 7.1260e-05 - acc: 0.6600\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 9.1432e-05 - acc: 0.6600\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.3807e-04 - acc: 0.6600\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0131 - acc: 0.6600\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0296 - acc: 0.6600\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0279 - acc: 0.6600\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 812us/step - loss: 0.0175 - acc: 0.6600\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 851us/step - loss: 0.0102 - acc: 0.6600 \n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 867us/step - loss: 0.0116 - acc: 0.6600\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.0114 - acc: 0.6600\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0062 - acc: 0.6600\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0069 - acc: 0.6600\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0064 - acc: 0.6600\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0059 - acc: 0.6600 \n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0057 - acc: 0.6600\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0051 - acc: 0.6600\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0062 - acc: 0.6600\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 837us/step - loss: 0.0113 - acc: 0.6600\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0097 - acc: 0.6600\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 808us/step - loss: 0.0081 - acc: 0.6600\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0040 - acc: 0.6600\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 855us/step - loss: 0.0050 - acc: 0.6600\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 849us/step - loss: 0.0050 - acc: 0.6600\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.6600\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0058 - acc: 0.6600\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0056 - acc: 0.6600 \n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0034 - acc: 0.6600 \n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 0.0079 - acc: 0.6600 \n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0078 - acc: 0.6600\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0031 - acc: 0.6600\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0039 - acc: 0.6600\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0016 - acc: 0.6600\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0030 - acc: 0.6600\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 0.0021 - acc: 0.6600 \n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 0.0024 - acc: 0.6600\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 8.4459e-04 - acc: 0.6600\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.0019 - acc: 0.6600 \n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0011 - acc: 0.6600\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0037 - acc: 0.6600 \n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 793us/step - loss: 0.0032 - acc: 0.6600\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 799us/step - loss: 0.0038 - acc: 0.6600 \n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0023 - acc: 0.6600 \n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.6308    - 0s 776us/step - loss: 0.0019 - acc: 0.6600\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 822us/step - loss: 0.0029 - acc: 0.6600 \n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0013 - acc: 0.6600 \n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0012 - acc: 0.6600\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 821us/step - loss: 0.0013 - acc: 0.6600\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 852us/step - loss: 5.5151e-04 - acc: 0.6600\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 814us/step - loss: 3.2076e-04 - acc: 0.6600\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 805us/step - loss: 1.9803e-04 - acc: 0.6600\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 873us/step - loss: 1.8902e-04 - acc: 0.6600\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 1.3428e-04 - acc: 0.6600\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 1.1908e-04 - acc: 0.6600\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 3.4689e-04 - acc: 0.6600\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 2.7455e-04 - acc: 0.6600\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 828us/step - loss: 0.0026 - acc: 0.6600\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 859us/step - loss: 0.0151 - acc: 0.6600\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 865us/step - loss: 0.0010 - acc: 0.6600\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 0.0434 - acc: 0.6600\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.0223 - acc: 0.6600\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0146 - acc: 0.6600\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 0.0036 - acc: 0.6600\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 8.5326e-04 - acc: 0.6600\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 4.9666e-04 - acc: 0.6600\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 3.0194e-04 - acc: 0.6600\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 2.4612e-04 - acc: 0.6600\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 2.0747e-04 - acc: 0.6600\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 1.6614e-04 - acc: 0.6600\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 776us/step - loss: 1.7924e-04 - acc: 0.6600\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 785us/step - loss: 1.2192e-04 - acc: 0.6600\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 803us/step - loss: 8.1027e-05 - acc: 0.6600\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 792us/step - loss: 8.4944e-05 - acc: 0.6600\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 7.7657e-05 - acc: 0.6600\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 2.6113e-04 - acc: 0.6600\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 950us/step - loss: 9.8343e-04 - acc: 0.6600\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0020 - acc: 0.6600\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 774us/step - loss: 5.2984e-04 - acc: 0.6600\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 802us/step - loss: 1.3753e-04 - acc: 0.6600\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 788us/step - loss: 6.9505e-05 - acc: 0.6600\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 3.9026e-05 - acc: 0.6600\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 4.5745e-05 - acc: 0.6600\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 6.1612e-05 - acc: 0.6600\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 2.4765e-05 - acc: 0.6600\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 2.0605e-05 - acc: 0.6600\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 1.7848e-05 - acc: 0.6600\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 3.8502e-05 - acc: 0.6600\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 7.4245e-05 - acc: 0.6600\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.5458e-04 - acc: 0.6600\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0348 - acc: 0.6600 \n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.6600\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0320 - acc: 0.6600\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0078 - acc: 0.6600\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.0140 - acc: 0.6600\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0182 - acc: 0.6600\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 0.0079 - acc: 0.6600\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 9.7040e-04 - acc: 0.6600\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 3.7281e-04 - acc: 0.6600\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 2.1787e-04 - acc: 0.6600\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 9.3468e-05 - acc: 0.6600\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 6.6553e-05 - acc: 0.6600\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 1.1619e-04 - acc: 0.6600\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 600us/step - loss: 7.6797e-05 - acc: 0.6600\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 8.8503e-05 - acc: 0.6600\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 6.2169e-05 - acc: 0.6600\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 740us/step - loss: 5.6605e-05 - acc: 0.6600\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 6.1753e-05 - acc: 0.6600\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 4.3929e-05 - acc: 0.6600\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 7.3369e-05 - acc: 0.6600\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 9.8640e-05 - acc: 0.6600\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 4.9528e-05 - acc: 0.6600\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 5.3105e-05 - acc: 0.6600\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 710us/step - loss: 4.3197e-05 - acc: 0.6600\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 6.3902e-05 - acc: 0.6600\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 5.1447e-05 - acc: 0.6600\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 8.8061e-05 - acc: 0.6600\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 5.9496e-05 - acc: 0.6600\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 4.9236e-05 - acc: 0.6600\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 4.8123e-05 - acc: 0.6600\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 1.8411e-04 - acc: 0.6600\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0114 - acc: 0.6600 \n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 0.0156 - acc: 0.6600\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 630us/step - loss: 0.0053 - acc: 0.6600\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 660us/step - loss: 0.0147 - acc: 0.6600 \n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 7.5765e-04 - acc: 0.6600\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0145 - acc: 0.6600\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0261 - acc: 0.6600 \n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 0.0174 - acc: 0.6600\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.0160 - acc: 0.6600\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0082 - acc: 0.6600\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0017 - acc: 0.6600 \n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.0010 - acc: 0.6600\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 4.9987e-04 - acc: 0.6600\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 3.0586e-04 - acc: 0.6600\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 1.4568e-04 - acc: 0.6600\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 1.5335e-04 - acc: 0.6600\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 730us/step - loss: 8.4368e-05 - acc: 0.6600\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 5.4806e-05 - acc: 0.6600\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 6.3723e-05 - acc: 0.6600\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.9444e-05 - acc: 0.6600\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 3.5330e-05 - acc: 0.6600\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 2.8558e-05 - acc: 0.6600\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 3.0873e-05 - acc: 0.6600\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 2.7359e-05 - acc: 0.6600\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 2.1915e-05 - acc: 0.6600\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1508e-05 - acc: 0.6600\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 820us/step - loss: 2.0973e-05 - acc: 0.6600\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 1.4277e-05 - acc: 0.6600\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 775us/step - loss: 2.3539e-05 - acc: 0.6600\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 879us/step - loss: 2.0547e-05 - acc: 0.6600\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 826us/step - loss: 1.7168e-05 - acc: 0.6600\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 1.3278e-05 - acc: 0.6600\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 970us/step - loss: 1.2398e-05 - acc: 0.6600\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 910us/step - loss: 1.4432e-05 - acc: 0.6600\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 2.8364e-05 - acc: 0.6600\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 1.3518e-05 - acc: 0.6600\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 1.0081e-04 - acc: 0.6600\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 980us/step - loss: 1.5078e-05 - acc: 0.6600\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 1.7514e-05 - acc: 0.6600\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 2.5061e-05 - acc: 0.6600\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 4.2091e-05 - acc: 0.6600\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 860us/step - loss: 6.3919e-05 - acc: 0.6600\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 1.1846e-04 - acc: 0.6600\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 680us/step - loss: 0.0013 - acc: 0.6600\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0024 - acc: 0.6600 \n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0261 - acc: 0.6600\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0338 - acc: 0.6600\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0062 - acc: 0.6600\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 0.0296 - acc: 0.6600\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 0.0047 - acc: 0.6600\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0021 - acc: 0.6600\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 640us/step - loss: 3.6775e-04 - acc: 0.6600\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 2.4315e-04 - acc: 0.6600\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 1.2131e-04 - acc: 0.6600\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 9.2222e-05 - acc: 0.6600\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 9.5488e-05 - acc: 0.6600\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 6.2410e-05 - acc: 0.6600\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 4.8734e-05 - acc: 0.6600\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 4.7335e-05 - acc: 0.6600\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 3.3799e-05 - acc: 0.6600\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 2.8722e-05 - acc: 0.6600\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 2.8739e-05 - acc: 0.6600\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 2.9464e-05 - acc: 0.6600\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 2.0879e-05 - acc: 0.6600\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 1.9182e-05 - acc: 0.6600\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 2.8768e-05 - acc: 0.6600\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 2.0797e-05 - acc: 0.6600\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 3.1624e-05 - acc: 0.6600\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 670us/step - loss: 8.8879e-06 - acc: 0.6600\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 6.2964e-06 - acc: 0.6600\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 1.0003e-05 - acc: 0.6600\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 1.2070e-05 - acc: 0.6600\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 5.7340e-06 - acc: 0.6600\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 4.3219e-06 - acc: 0.6600\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.8879e-06 - acc: 0.6600\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 960us/step - loss: 4.7774e-06 - acc: 0.6600\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 6.9744e-06 - acc: 0.6600\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 5.8078e-06 - acc: 0.6600\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 3.6673e-06 - acc: 0.6600\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 3.4782e-06 - acc: 0.6600\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 1.4969e-05 - acc: 0.6600\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 1.2900e-05 - acc: 0.6600\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 650us/step - loss: 3.6915e-05 - acc: 0.6600\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 570us/step - loss: 0.0086 - acc: 0.6600\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0114 - acc: 0.6600\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.0049 - acc: 0.6600 \n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 0.0102 - acc: 0.6600\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.0127 - acc: 0.6600\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 810us/step - loss: 0.0082 - acc: 0.6600 \n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 0.0076 - acc: 0.6600\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 807us/step - loss: 0.0017 - acc: 0.6600\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 7.0549e-05 - acc: 0.6600\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 4.7228e-05 - acc: 0.6600\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 2.2957e-05 - acc: 0.6600\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8334e-05 - acc: 0.6600\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 690us/step - loss: 6.9878e-06 - acc: 0.6600\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 750us/step - loss: 6.9337e-06 - acc: 0.6600\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 1.1322e-05 - acc: 0.6600\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 850us/step - loss: 9.0210e-06 - acc: 0.6600\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 1.3125e-05 - acc: 0.6600\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 720us/step - loss: 4.5165e-06 - acc: 0.6600\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 4.4359e-06 - acc: 0.6600\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 760us/step - loss: 2.0642e-06 - acc: 0.6600\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 780us/step - loss: 3.0413e-06 - acc: 0.6600\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 2.8675e-06 - acc: 0.6600\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 2.6319e-06 - acc: 0.6600\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 3.9088e-06 - acc: 0.6600\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 3.9761e-06 - acc: 0.6600\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 880us/step - loss: 3.6983e-06 - acc: 0.6600\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 5.2734e-06 - acc: 0.6600\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 790us/step - loss: 3.4655e-06 - acc: 0.6600\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 890us/step - loss: 3.6480e-06 - acc: 0.6600\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 840us/step - loss: 5.5425e-06 - acc: 0.6600\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 870us/step - loss: 1.0398e-05 - acc: 0.6600\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 830us/step - loss: 9.1553e-06 - acc: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21828d70280>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "\n",
    "# 여러 레이어를 쌓겠다.\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units = 256, activation=\"relu\", input_shape=(2,)))\n",
    "#model.add(layers.Dropout(0.5)) # 드롭아웃 : 오버피팅 막는법\n",
    "model.add(layers.Dense(units = 128, activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(units = 64, activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(units = 32, activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(units = 1,  activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = \"mse\",\n",
    "             metrics = ['acc'])\n",
    "\n",
    "model.fit(iris_pca_train, y_train, epochs = 1000, batch_size = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "certified-scanner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4268 - acc: 0.3800\n",
      "0.3799999952316284\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "Xtest_loss, Xtest_acc = model.evaluate(iris_pca_test,y_test)\n",
    "print(Xtest_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "introductory-minister",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.5924777e-01]\n",
      " [ 1.9782808e+00]\n",
      " [ 1.9962261e+00]\n",
      " [-1.6186237e-03]\n",
      " [-3.0609965e-03]\n",
      " [ 7.2652102e-04]\n",
      " [ 9.7385049e-01]\n",
      " [ 9.7278595e-01]\n",
      " [ 1.9383402e+00]\n",
      " [ 9.1430521e-01]\n",
      " [ 9.9283135e-01]\n",
      " [ 6.6000223e-04]\n",
      " [-1.0444522e-03]\n",
      " [ 1.5685737e-02]\n",
      " [-5.3297281e-03]\n",
      " [-5.7873130e-03]\n",
      " [ 1.2968752e+00]\n",
      " [-8.6009502e-05]\n",
      " [-7.1383715e-03]\n",
      " [ 1.3392818e+00]\n",
      " [ 9.8587865e-01]\n",
      " [ 9.9321431e-01]\n",
      " [ 1.9205997e+00]\n",
      " [ 1.1247940e+00]\n",
      " [ 9.3827373e-01]\n",
      " [ 2.0434823e+00]\n",
      " [ 9.9567354e-01]\n",
      " [ 9.9379230e-01]\n",
      " [ 9.4962603e-01]\n",
      " [-2.7047992e-03]\n",
      " [ 1.9601383e+00]\n",
      " [-1.5666485e-03]\n",
      " [ 4.1850895e-02]\n",
      " [ 9.5943987e-01]\n",
      " [ 1.3604298e+00]\n",
      " [ 9.9564302e-01]\n",
      " [ 2.0121047e+00]\n",
      " [ 2.0434632e+00]\n",
      " [ 9.9381173e-01]\n",
      " [ 4.2220831e-02]\n",
      " [ 2.0252738e+00]\n",
      " [ 9.9496818e-01]\n",
      " [-3.6051869e-03]\n",
      " [ 1.9714921e+00]\n",
      " [ 1.9956355e+00]\n",
      " [ 6.6751838e-03]\n",
      " [ 1.0182060e+00]\n",
      " [-2.2410750e-03]\n",
      " [ 9.9021757e-01]\n",
      " [ 1.9951580e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "Ttest = model.predict(iris_pca_test)\n",
    "                \n",
    "print(Ttest) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "skilled-hampton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행 중에 가장 큰 애를 가져온다.\n",
    "# 이를 y_test와 비교하면 된다!\n",
    "np.argmax(Ttest, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "limiting-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 0, 2, 2, 2, 2, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 0, 2, 2,\n",
       "       0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2,\n",
       "       0, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-warren",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
